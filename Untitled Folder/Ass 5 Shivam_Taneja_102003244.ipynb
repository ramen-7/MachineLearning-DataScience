{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1b9076a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8293d45",
   "metadata": {},
   "source": [
    "# Question 1, 1 vs All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "97960fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "class LogisticRegression():\n",
    "    \n",
    "    def __init__(self, learning_rate=0.01, iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterations = iterations\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        \n",
    "        for _ in range(self.iterations):\n",
    "            linear_predictions = np.dot(X, self.weights) + self.bias\n",
    "            predictions = sigmoid(linear_predictions)\n",
    "            \n",
    "            dW = (1/n_samples) * np.dot(X.T, (predictions - y))\n",
    "            db = (1/n_samples) * np.sum(predictions - y)\n",
    "        \n",
    "            self.weights = self.weights - self.learning_rate*dW\n",
    "            self.bias = self.bias - self.learning_rate*db\n",
    "            \n",
    "    def predict(self, X):\n",
    "        linear_predictions = np.dot(X, self.weights) + self.bias\n",
    "        y_pred = sigmoid(linear_predictions)\n",
    "        prob = sigmoid(linear_predictions)\n",
    "        final_pred = [0 if y <= 0.5 else 1 for y in y_pred]\n",
    "        return final_pred, prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d573401",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "X, y = load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9449c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1076a3b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "674c7a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "setosa = []\n",
    "versicolor = []\n",
    "virginica = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6405523b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_s = [1 if i == 0 else 0 for i in y]\n",
    "y_v = [1 if i == 1 else 0 for i in y]\n",
    "y_v2 = [1 if i == 2 else 0 for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1b6cc79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_s)\n",
    "print(y_v)\n",
    "print(y_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "90edbe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelSetosa = LogisticRegression()\n",
    "modelSetosa.fit(X, y_s)\n",
    "modelVersicolor = LogisticRegression()\n",
    "modelVersicolor.fit(X, y_v)\n",
    "modelVirginica = LogisticRegression()\n",
    "modelVirginica.fit(X, y_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "66b0d43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "setosa, predSetosa = modelSetosa.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c939725d",
   "metadata": {},
   "outputs": [],
   "source": [
    "versicolor, predVersicolor = modelVersicolor.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9a1d4424",
   "metadata": {},
   "outputs": [],
   "source": [
    "virginica, predVirginica = modelVirginica.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1db53b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.28323906e-01, 8.85795192e-01, 9.10987254e-01, 8.71383117e-01,\n",
       "       9.32539498e-01, 9.19454418e-01, 9.06303421e-01, 9.08518884e-01,\n",
       "       8.60932790e-01, 8.86940640e-01, 9.35723297e-01, 8.90444410e-01,\n",
       "       8.89756422e-01, 9.16489534e-01, 9.70729228e-01, 9.63326345e-01,\n",
       "       9.53594417e-01, 9.23772655e-01, 9.23417881e-01, 9.32350037e-01,\n",
       "       8.91737279e-01, 9.21653168e-01, 9.57195826e-01, 8.50327692e-01,\n",
       "       8.39483825e-01, 8.55854381e-01, 8.82442117e-01, 9.19898786e-01,\n",
       "       9.23866389e-01, 8.68167586e-01, 8.60531018e-01, 9.06326649e-01,\n",
       "       9.55152905e-01, 9.64807799e-01, 8.80101045e-01, 9.27765312e-01,\n",
       "       9.43483545e-01, 9.34998364e-01, 8.87143019e-01, 9.10715096e-01,\n",
       "       9.31820516e-01, 7.98846266e-01, 9.04270809e-01, 8.78111552e-01,\n",
       "       8.77506068e-01, 8.76023414e-01, 9.27093312e-01, 8.95861996e-01,\n",
       "       9.34097718e-01, 9.12996848e-01, 5.44558638e-02, 5.80195524e-02,\n",
       "       3.44445280e-02, 4.80350672e-02, 3.64424901e-02, 3.88399104e-02,\n",
       "       4.38362927e-02, 1.38615943e-01, 4.63813492e-02, 6.79375185e-02,\n",
       "       7.86022829e-02, 6.51555898e-02, 6.03440572e-02, 3.32340212e-02,\n",
       "       1.39330884e-01, 7.00788961e-02, 3.97477859e-02, 7.68069010e-02,\n",
       "       2.27709064e-02, 7.61221341e-02, 2.76226866e-02, 8.57233845e-02,\n",
       "       1.72117201e-02, 3.45800128e-02, 6.68634232e-02, 6.27346203e-02,\n",
       "       3.16086315e-02, 2.27859036e-02, 4.03241933e-02, 1.51443160e-01,\n",
       "       7.81429447e-02, 9.49699736e-02, 8.90274046e-02, 1.33653464e-02,\n",
       "       3.77579134e-02, 5.85897259e-02, 4.34030747e-02, 3.35451682e-02,\n",
       "       7.84334137e-02, 5.71689534e-02, 3.79645121e-02, 4.18241809e-02,\n",
       "       7.14653938e-02, 1.31018972e-01, 5.28313946e-02, 7.46336594e-02,\n",
       "       6.44083293e-02, 6.36059924e-02, 2.12968264e-01, 6.78097340e-02,\n",
       "       3.71625376e-03, 1.04102789e-02, 5.27071600e-03, 7.35091624e-03,\n",
       "       4.86842643e-03, 2.15999062e-03, 1.86350323e-02, 3.44574301e-03,\n",
       "       4.23526046e-03, 5.36612306e-03, 1.84391026e-02, 9.11985182e-03,\n",
       "       8.72684105e-03, 9.15330844e-03, 8.20294862e-03, 1.10441493e-02,\n",
       "       9.82163636e-03, 3.73102422e-03, 8.66598772e-04, 1.04826748e-02,\n",
       "       7.04031293e-03, 1.35381571e-02, 1.70415049e-03, 1.69479454e-02,\n",
       "       8.34551198e-03, 6.84477512e-03, 2.08689253e-02, 2.10750837e-02,\n",
       "       5.65170025e-03, 8.71258466e-03, 4.05049771e-03, 6.96371665e-03,\n",
       "       5.29012727e-03, 1.69040623e-02, 6.90451142e-03, 4.04225128e-03,\n",
       "       7.80529922e-03, 1.04758502e-02, 2.37042158e-02, 1.13508559e-02,\n",
       "       6.60147174e-03, 1.53812444e-02, 1.04102789e-02, 5.11890463e-03,\n",
       "       6.40938722e-03, 1.15282383e-02, 1.14564560e-02, 1.33163531e-02,\n",
       "       1.08635125e-02, 1.49832852e-02])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predSetosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bd99a231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15495558, 0.19791346, 0.17584211, 0.19497271, 0.14773974,\n",
       "       0.13416661, 0.16249561, 0.16763215, 0.20923332, 0.19600067,\n",
       "       0.14344235, 0.17293845, 0.20040677, 0.18672746, 0.1119966 ,\n",
       "       0.0971088 , 0.11955471, 0.1532144 , 0.14189846, 0.13563967,\n",
       "       0.17572599, 0.14101524, 0.13291964, 0.17940743, 0.18756498,\n",
       "       0.20822815, 0.16851216, 0.15902321, 0.16245667, 0.1906576 ,\n",
       "       0.19947899, 0.16269432, 0.11889519, 0.10768689, 0.19390412,\n",
       "       0.17014374, 0.14952161, 0.14971895, 0.19450063, 0.16731508,\n",
       "       0.14926898, 0.26358506, 0.176833  , 0.15691162, 0.15016561,\n",
       "       0.19615976, 0.14116852, 0.18101429, 0.14372199, 0.17121364,\n",
       "       0.34637491, 0.33164643, 0.37247545, 0.42740421, 0.39265671,\n",
       "       0.39549798, 0.33086538, 0.37092071, 0.38457397, 0.36219505,\n",
       "       0.44258718, 0.33816468, 0.44885908, 0.39194217, 0.3148489 ,\n",
       "       0.33877468, 0.3622461 , 0.38697676, 0.47213687, 0.39700883,\n",
       "       0.34741524, 0.35470747, 0.46078371, 0.41241874, 0.3624692 ,\n",
       "       0.3525105 , 0.41008829, 0.38881251, 0.37372672, 0.35494645,\n",
       "       0.4036649 , 0.39894329, 0.36522032, 0.44654785, 0.3632975 ,\n",
       "       0.30535278, 0.35822298, 0.45546853, 0.338283  , 0.39906171,\n",
       "       0.42008192, 0.37037002, 0.38667674, 0.38412407, 0.38637993,\n",
       "       0.34822291, 0.35852882, 0.36352088, 0.33099867, 0.36440331,\n",
       "       0.40242789, 0.43778504, 0.44577928, 0.4501561 , 0.43770933,\n",
       "       0.50049169, 0.42944614, 0.5020738 , 0.52266895, 0.36396298,\n",
       "       0.36083325, 0.45071577, 0.41509054, 0.45578447, 0.40723387,\n",
       "       0.36736698, 0.42652037, 0.38975069, 0.57587462, 0.5145046 ,\n",
       "       0.3958335 , 0.40529468, 0.54065714, 0.42209232, 0.38934795,\n",
       "       0.43441683, 0.40049812, 0.38106476, 0.45414752, 0.45357629,\n",
       "       0.49627604, 0.37163148, 0.45083803, 0.43375287, 0.50833223,\n",
       "       0.45212732, 0.36065849, 0.41283658, 0.37384232, 0.39252553,\n",
       "       0.39982022, 0.36297881, 0.43778504, 0.41227702, 0.37672127,\n",
       "       0.3854601 , 0.4557135 , 0.39608319, 0.349123  , 0.39784288])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predVersicolor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b2eb81a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00975504, 0.01601516, 0.01420709, 0.02028566, 0.00970205,\n",
       "       0.00969242, 0.01584742, 0.01251245, 0.0239913 , 0.01537007,\n",
       "       0.00769444, 0.01595009, 0.01583805, 0.01594917, 0.00339342,\n",
       "       0.00441719, 0.00624821, 0.01054953, 0.00787724, 0.0094679 ,\n",
       "       0.01191023, 0.01100939, 0.00818695, 0.01975531, 0.02208937,\n",
       "       0.01862201, 0.01630875, 0.01017759, 0.00980832, 0.01968891,\n",
       "       0.01979535, 0.0111905 , 0.00608254, 0.00447636, 0.0166142 ,\n",
       "       0.01041816, 0.00667961, 0.00959407, 0.02004141, 0.01170183,\n",
       "       0.0101117 , 0.03339723, 0.01735601, 0.01772824, 0.01584834,\n",
       "       0.01850246, 0.00976821, 0.01693528, 0.00822976, 0.01205949,\n",
       "       0.25190835, 0.30495201, 0.34366545, 0.43406288, 0.38041224,\n",
       "       0.44664471, 0.37075795, 0.28019209, 0.31279239, 0.40453043,\n",
       "       0.37828091, 0.33846918, 0.31684934, 0.43576399, 0.22874562,\n",
       "       0.24165006, 0.4663419 , 0.29140777, 0.51118884, 0.32114372,\n",
       "       0.5210771 , 0.26142346, 0.54973172, 0.41501477, 0.27221984,\n",
       "       0.26843914, 0.3660882 , 0.45778201, 0.41757576, 0.1960387 ,\n",
       "       0.32782195, 0.2874538 , 0.27855974, 0.63569918, 0.50019042,\n",
       "       0.34975213, 0.32461037, 0.40970981, 0.3239766 , 0.39845858,\n",
       "       0.46959493, 0.39119281, 0.31697949, 0.28130272, 0.40010469,\n",
       "       0.31608441, 0.34991197, 0.29989644, 0.19699281, 0.34146845,\n",
       "       0.83495002, 0.71700289, 0.70507838, 0.71465491, 0.77675638,\n",
       "       0.78701322, 0.70358998, 0.73390401, 0.76157997, 0.7112916 ,\n",
       "       0.54181572, 0.67789382, 0.65305067, 0.7525968 , 0.77761882,\n",
       "       0.66685911, 0.64532983, 0.69900261, 0.88313953, 0.67557531,\n",
       "       0.68944774, 0.70052136, 0.80492177, 0.57206668, 0.66855078,\n",
       "       0.6296073 , 0.54342977, 0.55131587, 0.76149627, 0.57387303,\n",
       "       0.70637878, 0.55400473, 0.77556405, 0.55006901, 0.7225601 ,\n",
       "       0.69936279, 0.73617933, 0.64406995, 0.54069917, 0.59405345,\n",
       "       0.72609621, 0.55158018, 0.71700289, 0.74774053, 0.73459012,\n",
       "       0.62868616, 0.65172185, 0.60465107, 0.68861304, 0.637111  ])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predVirginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d0403e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = []\n",
    "results = [setosa, versicolor, virginica]\n",
    "probResults = [predSetosa, predVersicolor, predVirginica]\n",
    "for i in range(len(X)):\n",
    "    clas = []\n",
    "    for j in results:\n",
    "        if(j[i] == 1):\n",
    "            clas.append(1)\n",
    "        else:\n",
    "            clas.append(0)\n",
    "    m = -1\n",
    "    max = 0\n",
    "    for j in range(len(clas)):\n",
    "        if clas[j] == 1:\n",
    "            if probResults[j][i] > max:\n",
    "                max = probResults[j][i]\n",
    "                m = j\n",
    "    final.append(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "51159855",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(final)):\n",
    "    if final[i] == -1:\n",
    "        final[i] = 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d256ff0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ecada9",
   "metadata": {},
   "source": [
    "### Accuracy of model 1vsAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ef5654a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(final, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0bb309",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7166474c",
   "metadata": {},
   "source": [
    "#### No regularization alpha = 10, iteration = 1000, lamda = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "2543128c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "class LogisticRegression():\n",
    "    \n",
    "    def __init__(self, learning_rate=10, iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterations = iterations\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        \n",
    "        for _ in range(self.iterations):\n",
    "            linear_predictions = np.dot(X, self.weights) + self.bias\n",
    "            predictions = sigmoid(linear_predictions)\n",
    "            \n",
    "            dW = (1/n_samples) * np.dot(X.T, (predictions - y))\n",
    "            db = (1/n_samples) * np.sum(predictions - y)\n",
    "        \n",
    "            self.weights = self.weights - self.learning_rate*dW\n",
    "            self.bias = self.bias - self.learning_rate*db\n",
    "            \n",
    "    def predict(self, X):\n",
    "        linear_predictions = np.dot(X, self.weights) + self.bias\n",
    "        y_pred = sigmoid(linear_predictions)\n",
    "        final_pred = [0 if y <= 0.5 else 1 for y in y_pred]\n",
    "        return final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "abbf2347",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgeLogisticRegression():\n",
    "    \n",
    "    def __init__(self, learning_rate=10, iterations=1000, lamda=0.2):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterations = iterations\n",
    "        self.lamda = lamda\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        \n",
    "        for _ in range(self.iterations):\n",
    "            linear_predictions = np.dot(X, self.weights) + self.bias\n",
    "            predictions = sigmoid(linear_predictions)\n",
    "            \n",
    "            dW = (1/n_samples) * np.dot(X.T, (predictions - y))\n",
    "            db = (1/n_samples) * np.sum(predictions - y)\n",
    "        \n",
    "            self.weights = self.weights*(self.learning_rate*self.lamda) - self.learning_rate*dW\n",
    "            self.bias = self.bias*(self.learning_rate*self.lamda) - self.learning_rate*db\n",
    "            \n",
    "    def predict(self, X):\n",
    "        linear_predictions = np.dot(X, self.weights) + self.bias\n",
    "        y_pred = sigmoid(linear_predictions)\n",
    "        final_pred = [0 if y <= 0.5 else 1 for y in y_pred]\n",
    "        return final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "143bf031",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('exam6.txt', names=['test1', 'test2', 'result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a4f788bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test1</th>\n",
       "      <th>test2</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.051267</td>\n",
       "      <td>0.699560</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.092742</td>\n",
       "      <td>0.684940</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.213710</td>\n",
       "      <td>0.692250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.375000</td>\n",
       "      <td>0.502190</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.513250</td>\n",
       "      <td>0.465640</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>-0.720620</td>\n",
       "      <td>0.538740</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>-0.593890</td>\n",
       "      <td>0.494880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>-0.484450</td>\n",
       "      <td>0.999270</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>-0.006336</td>\n",
       "      <td>0.999270</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.632650</td>\n",
       "      <td>-0.030612</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        test1     test2  result\n",
       "0    0.051267  0.699560       1\n",
       "1   -0.092742  0.684940       1\n",
       "2   -0.213710  0.692250       1\n",
       "3   -0.375000  0.502190       1\n",
       "4   -0.513250  0.465640       1\n",
       "..        ...       ...     ...\n",
       "113 -0.720620  0.538740       0\n",
       "114 -0.593890  0.494880       0\n",
       "115 -0.484450  0.999270       0\n",
       "116 -0.006336  0.999270       0\n",
       "117  0.632650 -0.030612       0\n",
       "\n",
       "[118 rows x 3 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6da714d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['result'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4f74d9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a7ccf087",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "31865e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7d9ece71",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "383b2a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "1a43aec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelR = RidgeLogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "26b9362d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shvmt\\AppData\\Local\\Temp/ipykernel_21524/2207607576.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1 + np.exp(-x))\n"
     ]
    }
   ],
   "source": [
    "modelR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "00973ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shvmt\\AppData\\Local\\Temp/ipykernel_21524/2207607576.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1 + np.exp(-x))\n"
     ]
    }
   ],
   "source": [
    "y_pred2 = modelR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "367034a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy without regression 0.5\n",
      "Accuracy with regression 0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(f\"Accuracy without regression {accuracy_score(y_pred, y_test)}\")\n",
    "print(f\"Accuracy with regression {accuracy_score(y_pred2, y_test)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
